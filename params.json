{
  "name": "Source Separation Audio Project",
  "tagline": "Application to source separate a piece of music by using the most accurate source separation algorithm for that genre of music.",
  "body": "### Source Separation Introduction\r\nAudio source separation is a well known problem in the field of signal processing. In class, we implemented the REPET algorithm so separate foreground vocal from background music. In this project, we test many other source separation algorithms and test them against different genres of music. Our final deliverable that will be able to take in a musical piece of a certain genre and separate the audio based on the best algorithm for that genre.\r\n\r\n### Web Application\r\n\r\n# **[DeVoiceIfy Web Application](https://serene-fjord-33111.herokuapp.com/)**\r\n\r\nOur web application allows a user to input an audio file and then talk over the signal to create a mixed audio signal. Our web application then processes the mixed signal using a separating algorithm, and outputs the foreground and background signal for download.\r\n\r\n_NOTE: Our web application is hosted for free on Heroku. Because of this, the webpage may take up to 30 seconds to load initially._\r\n\r\n### Motivation\r\n\r\nMany source separation algorithms have been researched and proven to have modest success in separating foreground audio, such as vocals, from background audio, such as rhythmic music. \r\n\r\nHowever, our group was wondering if some algorithms had better performance in certain circumstances? Would there be situations where for one type of audio signal algorithm X would work best, while for another algorithm Y worked best? We wished to find the answer to that question.\r\n\r\nSpecifically, we looked at typing music by genre. A genre of music has general trends in regards to tempo, beat, and rhythm. Would those trends lead to better performance of some algorithms over others? We are asking: \r\n\r\n_**Is the performance of a source separation algorithm dependent on the source’s genre of music?**_\r\n\r\n\r\n### Prior Work\r\nThere has been much literature in the field of source separation, with many algorithms that have been implemented for source separation. The following papers have influenced our work so far, showcasing different algorithms that have been used to separate sources.\r\n\r\n* Celik, Abdullah, Milutin Stanacevic, and Gert Cauwenberghs. [\"Mixed­signal real­time adaptive blind source separation.\"](http://isn.ucsd.edu/pubs/iscas04_ica.pdf)\r\n Circuits and Systems, 2004. ISCAS'04. Proceedings of the 2004 International Symposium on. Vol. 5. IEEE, 2004.\r\n* Duan, Zhiyao, Gautham J. Mysore, and Paris Smaragdis. [\"Online PLCA for real­time semi­supervised source separation.\"](https://ccrma.stanford.edu/~gautham/Site/Publications_files/duan­lvaica2012.pdf)\r\n Latent Variable Analysis and Signal Separation. Springer Berlin Heidelberg, 2012. 34­41.\r\n* Mysore, Gautham J., and Paris Smaragdis. [\"A non­negative approach to semi­supervised separation of speech from noise with the use of temporal dynamics.\"](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5946317) Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011.\r\n* Vincent, Emmanuel, Rémi Gribonval, and Cédric Févotte. [\"Performance measurement in blind audio source separation.\"](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1643671) Audio, Speech, and Language Processing, IEEE Transactions on 14.4 (2006): 1462­1469.\r\n\r\n### System Overview \r\n\r\n**Analysis Workflow**\r\nTo quantify the analysis, we created an automated system that took in clips of audio files and attempted to separate the audio tracks. The system is populated with a dataset of audio snippets and audio snippets with vocal overlay, each within a genre of music. The system then takes each mixed audio signal and attempts to separate the audio signals based on each algorithm. The separations are then compared to the originals to create an accuracy score.\r\n\r\n**Application Workflow**\r\nThrough a web application, a person is able to separate audio based on a musical piece’s genre.  A user enters a audio snippet through a browser interface, along with the genre of that music. The user is then allowed to overlay a vocal audio track through the microphone. The system then processes the mixed audio signal using the source separation algorithm best suited for that genre. The separated audio is then available to the user.\r\n\r\n### Dataset and Methodology\r\n\r\nOur dataset set came from manually creating audio snippets from YouTube clips of musical performances, with no vocals. For testing, we overlayed a vocal track on those audio snippets. \r\n\r\nFor our testing we chose the genres of classical and rock. We believed each genre had distinct rhythm and flow. We hypothesized that because of this different, some algorithms would prove to work better than others.\r\n\r\nWe compared REpeating Pattern Extraction Technique (REPET), Nonnegative Matrix Decomposition (NMF), and TruncatedSVD (SVD). We chose these algorithms based on literature in the field and feasibility of implementation. \r\n\r\nOur methodology consisted of running each mixed signal against each source separation algorithm. The computed foreground and background signals were then compared to the original musical track and the vocal overlay. Similarly was computed using cosine similarity.\r\n\r\n### Results\r\n\r\n![Source Separation Results](http://i.imgur.com/6BgV3ko.png)\r\n\r\n### Analysis\r\n\r\nOur analysis showed it was easier to separate classical music than rock. An interesting note was that it was easier to separate out the rock background than classical. This could be due to the repetitive nature of the background signal. \r\n\r\nOur data said NMF performed best regardless of the genre. However, when looking at background and foreground individually, we see REPET worked well on background signals and poor on vocal. SVD had reverse performance. This indicates that an algorithm should be selected based on which signal is most important to retain.\r\n\r\n### Conclusion \r\nIn conclusion, we saw that genre had no affect on performance because NMF was superior. We saw performance improve when separating classical music and saw performance depend heavily on if the signal was background or foreground.\r\n\r\nNext steps would be to test these results against a larger sample of data. Moreover, we could try testing different algorithms and genres. With that larger test, we could further develop our application to take take advantage of the differing performances of algorithms. \r\n\r\n### Team\r\n* Sam Cohen (samcohen2017@u.northwestern.edu)\r\n* Zavier Henry (zavierhenry2016@u.northwestern.edu)\r\n* Shawn Caeiro (shawncaeiro2016@u.northwestern.edu)\r\n\r\n### Credits\r\nThis project was created for Bryan Pardo's EECS 352 at Northwestern University.\r\n",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}