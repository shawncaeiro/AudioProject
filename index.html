<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Source Separation Audio Project by shawncaeiro</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Source Separation Audio Project</h1>
        <h2>Application to source separate a piece of music by using the most accurate source separation algorithm for that genre of music.</h2>
        <a href="https://github.com/shawncaeiro/AudioProject" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>
<a id="source-separation-introduction" class="anchor" href="#source-separation-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Source Separation Introduction</h3>

<p>Audio source separation is a well known problem in the field of signal processing. In class, we implemented the REPET algorithm so separate foreground vocal from background music. In this project, we test many other source separation algorithms and test them against different genres of music. Our final deliverable that will be able to take in a musical piece of a certain genre and separate the audio based on the best algorithm for that genre.</p>

<h3>
<a id="web-application" class="anchor" href="#web-application" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Web Application</h3>

<h2>
<a id="devoiceify-web-application" class="anchor" href="#devoiceify-web-application" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong><a href="https://serene-fjord-33111.herokuapp.com/">DeVoiceIfy Web Application</a></strong>
</h2>

<h3>
<a id="motivation" class="anchor" href="#motivation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Motivation</h3>

<p>Many source separation algorithms have been researched and proven to have modest success in separating foreground audio, such as vocals, from background audio, such as rhythmic music. </p>

<p>However, our group was wondering if some algorithms had better performance in certain circumstances? Would there be situations where for one type of audio signal algorithm X would work best, while for another algorithm Y worked best? We wished to find the answer to that question.</p>

<p>Specifically, we looked at typing music by genre. A genre of music has general trends in regards to tempo, beat, and rhythm. Would those trends lead to better performance of some algorithms over others? We are asking: </p>

<p><em><strong>Is the performance of a source separation algorithm dependent on the source’s genre of music?</strong></em></p>

<h3>
<a id="prior-work" class="anchor" href="#prior-work" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prior Work</h3>

<p>There has been much literature in the field of source separation, with many algorithms that have been implemented for source separation. The following papers have influenced our work so far, showcasing different algorithms that have been used to separate sources.</p>

<ul>
<li>Celik, Abdullah, Milutin Stanacevic, and Gert Cauwenberghs. <a href="http://isn.ucsd.edu/pubs/iscas04_ica.pdf">"Mixed­signal real­time adaptive blind source separation."</a>
Circuits and Systems, 2004. ISCAS'04. Proceedings of the 2004 International Symposium on. Vol. 5. IEEE, 2004.</li>
<li>Duan, Zhiyao, Gautham J. Mysore, and Paris Smaragdis. <a href="https://ccrma.stanford.edu/%7Egautham/Site/Publications_files/duan%C2%ADlvaica2012.pdf">"Online PLCA for real­time semi­supervised source separation."</a>
Latent Variable Analysis and Signal Separation. Springer Berlin Heidelberg, 2012. 34­41.</li>
<li>Mysore, Gautham J., and Paris Smaragdis. <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5946317">"A non­negative approach to semi­supervised separation of speech from noise with the use of temporal dynamics."</a> Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011.</li>
<li>Vincent, Emmanuel, Rémi Gribonval, and Cédric Févotte. <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1643671">"Performance measurement in blind audio source separation."</a> Audio, Speech, and Language Processing, IEEE Transactions on 14.4 (2006): 1462­1469.</li>
</ul>

<h3>
<a id="system-overview" class="anchor" href="#system-overview" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>System Overview</h3>

<p><strong>Analysis Workflow</strong>
To quantify the analysis, we created an automated system that took in clips of audio files and attempted to separate the audio tracks. The system is populated with a dataset of audio snippets and audio snippets with vocal overlay, each within a genre of music. The system then takes each mixed audio signal and attempts to separate the audio signals based on each algorithm. The separations are then compared to the originals to create an accuracy score.</p>

<p><strong>Application Workflow</strong>
Through a web application, a person is able to separate audio based on a musical piece’s genre.  A user enters a audio snippet through a browser interface, along with the genre of that music. The user is then allowed to overlay a vocal audio track through the microphone. The system then processes the mixed audio signal using the source separation algorithm best suited for that genre. The separated audio is then available to the user.</p>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h1>

<p><img src="http://i.imgur.com/6BgV3ko.png" alt="Source Separation Results"></p>

<h3>
<a id="analysis" class="anchor" href="#analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis</h3>

<p>Our analysis showed it was easier to separate classical music than rock. An interesting note was that it was easier to separate out the rock background than classical. This could be due to the repetitive nature of the background signal. </p>

<p>Our data said NMF performed best regardless of the genre. However, when looking at background and foreground individually, we see REPET worked well on background signals and poor on vocal. SVD had reverse performance. This indicates that an algorithm should be selected based on which signal is most important to retain.</p>

<h3>
<a id="dataset-and-methodology" class="anchor" href="#dataset-and-methodology" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dataset and Methodology</h3>

<p>Our dataset set came from manually creating audio snippets from YouTube clips of musical performances, with no vocals. For testing, we overlayed a vocal track on those audio snippets. </p>

<p>For our testing we chose the genres of classical and rock. We believed each genre had distinct rhythm and flow. We hypothesized that because of this different, some algorithms would prove to work better than others.</p>

<p>We compared REpeating Pattern Extraction Technique (REPET), Nonnegative Matrix Decomposition (NMF), and TruncatedSVD (SVD). We chose these algorithms based on literature in the field and feasibility of implementation. </p>

<p>Our methodology consisted of running each mixed signal against each source separation algorithm. The computed foreground and background signals were then compared to the original musical track and the vocal overlay. Similarly was computed using cosine similarity.</p>

<h3>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusion</h3>

<p>In conclusion, we saw that genre had no affect on performance because NMF was superior. We saw performance improve when separating classical music and saw performance depend heavily on if the signal was background or foreground.</p>

<p>Next steps would be to test these results against a larger sample of data. Moreover, we could try testing different algorithms and genres. With that larger test, we could further develop our application to take take advantage of the differing performances of algorithms. </p>

<h3>
<a id="team" class="anchor" href="#team" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Team</h3>

<ul>
<li>Sam Cohen (<a href="mailto:samcohen2017@u.northwestern.edu">samcohen2017@u.northwestern.edu</a>)</li>
<li>Zavier Henry (<a href="mailto:zavierhenry2016@u.northwestern.edu">zavierhenry2016@u.northwestern.edu</a>)</li>
<li>Shawn Caeiro (<a href="mailto:shawncaeiro2016@u.northwestern.edu">shawncaeiro2016@u.northwestern.edu</a>)</li>
</ul>

<h3>
<a id="credits" class="anchor" href="#credits" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Credits</h3>

<p>This project was created for Bryan Pardo's EECS 352 at Northwestern University.</p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/shawncaeiro/AudioProject/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/shawncaeiro/AudioProject/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/shawncaeiro/AudioProject"></a> is maintained by <a href="https://github.com/shawncaeiro">shawncaeiro</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
